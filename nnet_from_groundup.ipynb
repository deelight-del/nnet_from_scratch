{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Doing Neural Nets from scratch using classification between digits 6 and digits 2 Image Classifier"
      ],
      "metadata": {
        "id": "ysulUcvHKgf3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Deep Learning can be taunting especially with the name and various jargon associated with the field. Today, after reading through [fastai chapter 4 notebook](https://colab.research.google.com/github/fastai/fastbook/blob/master/04_mnist_basics.ipynb) on deep learning taught by Jeremy Howard on YouTube via this [link](https://course.fast.ai/Lessons/lesson3.html) as neural net foundations, I decided to go through the model building from scratch. The data for this project was obtained from Fastai URLs class.\n",
        "\n",
        "**What are deep learning models?** Deep learning models are functions. Functions that do a specific thing. However, unlike normal functions that does a speicific task as defined by the programmer, deep learning models actually learn from the input itself and gives an output based on the parameters that it has learnt from the input. These parameters (and some other things) are what is stored in a deep learning model when you export it and use it for some sort of predictions. These parameters also called `weights and biases` are usually matrices of numbers that possess an extra function of being adjustable during the training/learning process. \n",
        "\n",
        "What I will be trying to do in this notebook will be to explain how neural nets work possibly in an intermediate or high level(less complicated) manner while avoiding as many jargons as possible.\n",
        "\n",
        "According to fastai chapter 4 notebook, there are seven steps, which I compress to six steps involved in building a neural network (neural net)/ deep learning model (DL model) and they are as follows:\n",
        "1. Initialize random model parameters\n",
        "2. Use the model to make prediction.\n",
        "3. Calculate the loss obtained by comparing the prediction with the actual targets using a selected loss function.\n",
        "4. Based on the loss function, calculate the gradients for each parameters.\n",
        "5. Step the parameters using the gradients obtained above.\n",
        "6. Repeat step 2 to 5 until you obtain desired result or time constraints.\n",
        "\n",
        "These steps will form the architecture of our entire process and also serves as the foundation of the building deep learning models. Each single step can be thus be made more complicated depending on the interest of the person, the challenge that is faced or other factors. My job here will be to use the simplest tools that I am familiar with while using fastai framework that is built on top of pytorch.\n",
        "\n",
        "Before we begin delving straight into working with the deep learning. We need a dataset to work with. As explained above the dataset has been obtained from zindi and will thus be used. Since we will be using simple neural networks, some few things are important for the images that we are working with.\n",
        "1. They should be of the same size and\n",
        "2. In order to save space and time for many of the matrix computations that we will be doing, we will need to convert our pictures to black and white."
      ],
      "metadata": {
        "id": "3MHqh8a5JFKt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gO1hMvRHnMoA",
        "outputId": "3732ba8c-b988-4675-df32-dad0dad5a458"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mHT991zYJBD4",
        "outputId": "0397afbd-0358-4db5-b61c-45b0a0685474"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[K     |████████████████████████████████| 719 kB 4.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 365 kB 37.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 4.9 MB 49.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 1.3 MB 53.9 MB/s \n",
            "\u001b[K     |████████████████████████████████| 212 kB 8.1 MB/s \n",
            "\u001b[K     |████████████████████████████████| 120 kB 59.5 MB/s \n",
            "\u001b[K     |████████████████████████████████| 115 kB 54.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 127 kB 53.2 MB/s \n",
            "\u001b[K     |████████████████████████████████| 6.6 MB 43.8 MB/s \n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -Uqq fastbook\n",
        "import fastbook\n",
        "fastbook.setup_book()\n",
        "\n",
        "from fastai.vision.all import *\n",
        "from fastbook import *\n",
        "\n",
        "matplotlib.rc('image', cmap='Greys')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Gathering Data.\n",
        "\n",
        "Since the dataset is already downloaded on my drive, I will thus proceed to load the dataset and divide it into a traing and validation set."
      ],
      "metadata": {
        "id": "KKWT1vD3YrVY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = untar_data(URLs.MNIST)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 37
        },
        "id": "RIzRsdLDJIu6",
        "outputId": "11b76449-b65c-45bc-c807-8c56ff101095"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      <progress value='15687680' class='' max='15683414' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      100.03% [15687680/15683414 00:00&lt;00:00]\n",
              "    </div>\n",
              "    "
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print((path/\"training\").ls().sorted()[:7])\n",
        "print((path/\"testing\").ls().sorted()[:7])\n",
        "#Select the first two objects in the list which are directories for images 2 and images 6"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sa7_DHZw6bt-",
        "outputId": "b6e69c5b-2895-4495-f33d-f3de324fbe36"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Path('/root/.fastai/data/mnist_png/training/0'), Path('/root/.fastai/data/mnist_png/training/1'), Path('/root/.fastai/data/mnist_png/training/2'), Path('/root/.fastai/data/mnist_png/training/3'), Path('/root/.fastai/data/mnist_png/training/4'), Path('/root/.fastai/data/mnist_png/training/5'), Path('/root/.fastai/data/mnist_png/training/6')]\n",
            "[Path('/root/.fastai/data/mnist_png/testing/0'), Path('/root/.fastai/data/mnist_png/testing/1'), Path('/root/.fastai/data/mnist_png/testing/2'), Path('/root/.fastai/data/mnist_png/testing/3'), Path('/root/.fastai/data/mnist_png/testing/4'), Path('/root/.fastai/data/mnist_png/testing/5'), Path('/root/.fastai/data/mnist_png/testing/6')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = (path/\"training\").ls().sorted()[:7] #Subset to extract 6 and 2 images\n",
        "valid_dir = (path/\"testing\").ls().sorted()[:7]"
      ],
      "metadata": {
        "id": "NLpx-FpcJI4S"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "six_images = train_dir[-1].ls() #obtain files in `six` images\n",
        "two_images = train_dir[2].ls()  #obtain files in `two` images"
      ],
      "metadata": {
        "id": "ePM2alcZJI7O"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "six_valid = valid_dir[-1].ls()\n",
        "two_valid = valid_dir[2].ls()"
      ],
      "metadata": {
        "id": "HseEAV0GU8Ik"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We already obtained the images data that we need to classify if an image is a 6 or a 2. The images need to be in the form of a dataset where the independent variable is a **vector** of each image and the dependent variable(our target) is label as \"6\" or \"2\".\n",
        "\n",
        "The kind of images that we are dealing with are black and white kind of images that can be represented as 2D arrays as we will see below.\n",
        "\n",
        "We procced to obtain vectors of each image and then join both six and two images to form our training set. The labels are also obtained and a dataset kind of object is formed by zipping both independent and dependent variables together. Talking about dependent variables, we will asssign `6` with 1 and `2` with 0. I.e. thse model will call true(1) when it is 6 and will call false when it is 2\n",
        "\n",
        "The same applies for the validation data"
      ],
      "metadata": {
        "id": "Tx6srFYr3yQk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Shape of a typical image 6 is:\", tensor(Image.open(six_images[0])).shape)\n",
        "print(\"Shape of a typical image 2 is:\", tensor(Image.open(two_images[0])).shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WyvztVbM8SNU",
        "outputId": "bbdc0884-193b-4181-9a4e-af4548d40f8b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of a typical image 6 is: torch.Size([28, 28])\n",
            "Shape of a typical image 2 is: torch.Size([28, 28])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Random opening of images\n",
        "Image.open(two_images[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "Cw7G4Idu9FdJ",
        "outputId": "69a96b0c-b900-4a52-9d97-bf8d6cafcbd2"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABMElEQVR4nL2RzyvDcRjHX7M1JQwhCq0hR0puDpLbTtRy9GsuSiv7B+TqZookFGmp1XIUUw5KstIuCqsZBwdprdWavXGwr74bu+59e57X834/PZ8PVF4Wc9FtpWYWXvZe/8wN7Gb1o0RPcUDbUiwlJeedTmcgr7jLxOqmJOnB1wvAouQ2QZ+k3IajUDXGtQ2ADYAxckfHIWP0PUOrydk502decl8UW6xRY2fVP3CIz3w5Y1NCl2VTN6WOciyg7Km1pNfsCwb9/TiCb9ovJl3e6KMkpQ+vpUiD0bYBOFcnuNoCr2sSyNRmPkzGNV2MtwAHkp4knYRCy78wErEDnlhOd9PtnhtJuoXCZ39pJ83gsCXpDwvq51h4Xjk3nOuSpDN3dckFFgD7iBui4VTZd6mgvgFYen8pA8hvNwAAAABJRU5ErkJggg==\n"
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Image.open(six_images[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 45
        },
        "id": "V1heBF9689Hm",
        "outputId": "49b34197-18a4-445b-b67b-3f93da533bb2"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAw0lEQVR4nGNgoCZYcVkSt+Snf+YQBhOGFPME7hfvcWhj7/j3rxeXmVX//u3gZsBuLLMhA8P1rzg0Vv77t48dh5zL33+7mXHIBV7699Udh5z863//inG59Mq/f7clcMiF/f130QO7FCP/qX//slGEEP5Uem/CwKCZhlVj3pd///79+/fnsS4WyUP//v27tfrQv/9PsUhq7fv3bzW7279/P7CZO+3fv3+7T+CQVPj279+/f7/747A6yW33v3Ol8VilhgQAAMoBUo6TGEGuAAAAAElFTkSuQmCC\n"
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.stack([tensor(Image.open(six_images[0])).view(-1, 28*28),\n",
        "             tensor(Image.open(six_images[1])).view(-1, 28*28)]).squeeze(1).shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z4sDRTSb0NQ_",
        "outputId": "5c625b65-1956-45e4-d0ab-e15041580a8d"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "six_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in six_images])\n",
        ".squeeze(1)).float()/255\n",
        "\n",
        "six_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A3iTEKyuJI-c",
        "outputId": "a5ac9209-92c3-41fc-e9f6-9027037128e7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5918, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in two_images])\n",
        ".squeeze(1)).float()/255\n",
        "\n",
        "\n",
        "two_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4jeGqyXzJJBj",
        "outputId": "3674e521-e920-409c-86f8-db61904d7144"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([5958, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Create six and two valid\n",
        "\n",
        "six_valid_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in six_valid])\n",
        ".squeeze(1)).float()/255\n",
        "\n",
        "six_valid_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I_wPP3rjWnHk",
        "outputId": "75bfd699-baa7-43e9-d2e7-1004061f6483"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([958, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "two_valid_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in two_valid])\n",
        ".squeeze(1)).float()/255\n",
        "\n",
        "two_valid_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cOqSTB_8W5PV",
        "outputId": "d1a1393b-5c51-4636-aca4-ea54c7d6b036"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1032, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "What the result of the above is showing us that each of the vectors contain a vector of each image. Vectors are 1D matrices. They have just one row. A list for instance can be called a vector because they contain their values in 1D.\n",
        "\n",
        "Let us pick a random vector in both vector stack and convert it back to a matrix of 28by28 and then show it as an image, to see if our transformation still matches."
      ],
      "metadata": {
        "id": "ZeQC2_oU-yfN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(two_vectors[189, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "xWELKtiBJJEQ",
        "outputId": "a032b566-7652-4157-ea8d-467bbdf780c7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(six_vectors[1900, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "mi8TLY8VJJTe",
        "outputId": "68773a1a-d2d3-4951-89f7-07e8e0c3ec0d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain train data and targets that combine both stacks\n",
        "two_target = L([0] * len(two_images))\n",
        "six_target = L([1] * len(six_images))\n",
        "\n",
        "train_target = two_target + six_target\n",
        "train_target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMsg8YD_JJXP",
        "outputId": "7d316fe5-6384-4062-fd9b-af5617548462"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [0,0,0,0,0,0,0,0,0,0]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(six_valid)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jElNZj5gXqR3",
        "outputId": "be539ec4-9988-495c-a781-45b105eede01"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "958"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Obtain valid data and targets that combine both stacks\n",
        "\n",
        "two_valid_targets = L([0] * len(two_valid))\n",
        "six_valid_targets = L([1] * len(six_valid))\n",
        "\n",
        "valid_target = two_valid_targets + six_valid_targets\n",
        "valid_target[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xw55QXMyXe7G",
        "outputId": "954bccae-04c6-4f27-ab66-2c6150e8ad51"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#10) [0,0,0,0,0,0,0,0,0,0]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_target[-6266:]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2AQ8mf9LDtjY",
        "outputId": "b5650729-b37c-4e47-ccc2-dda22e3a70fc"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(#6266) [0,0,0,0,0,0,0,0,0,0...]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = two_images + six_images\n",
        "\n",
        "train_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in train_data])\n",
        ".squeeze(1)).float()/255\n",
        "train_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z_E0P6JlJJfh",
        "outputId": "ae23ec85-9505-4044-df4e-93ed88249362"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11876, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_vectors.shape[1]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFGzQlw2-WPE",
        "outputId": "16bec2cd-0e49-4f75-da15-7da35fab522f"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "784"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Valid datapoints\n",
        "\n",
        "valid_data = two_valid + six_valid\n",
        "\n",
        "valid_vectors = (torch.stack([tensor(Image.open(i))\n",
        ".view(-1, 28*28) for i in valid_data])\n",
        ".squeeze(1)).float()/255\n",
        "\n",
        "valid_vectors.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9--wV_KRY1Kq",
        "outputId": "7c9ce2d6-0315-4775-e83a-bed09d9b632d"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1990, 784])"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#test the first and lastn set of vectors\n",
        "show_image(train_vectors[20, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "F8U7AeqpJJjA",
        "outputId": "1ce5ff3b-686b-4885-bdb6-55f0c3f3488b"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "show_image(train_vectors[-10, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "XFbRGGtxJJlw",
        "outputId": "2d284d9b-47e0-4e39-e6cb-e0bf574c1f9f"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show image for valid dataset\n",
        "show_image(valid_vectors[10, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "kPP7ddrQZcbb",
        "outputId": "b862b647-7c19-4e77-e4a9-d7e3985c1c85"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAEQAAABECAYAAAA4E5OyAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAHxklEQVR4nO2by08TXR+An2mn0yvS0kLaUnlpkKg0iAkQjRu8JKw0ce9f4c6N/4iJCzbuXLgxJkZDQlygidgotyDUcim3gtgOLW2nM9/i/WY+OuALvhaoX+bZYGbinHMezvmdc37nIGiahsX/sJ11BRoNS4gJS4gJS4gJS4gJ8Yj3/89TkHDYQ6uHmLCEmLCEmLCEmLCEmLCEmDhq2v1lNE1D0zRUVUVRFOO5IAjY7XZUVUVVVWw2G6IoIggCgnDoDHgm1F2IqqqUy2WKxSLr6+vou2mv14vf72d3d5ednR38fj+BQABRFHE4HPWuxr+mbkI0TUNRFEqlEmtra2xvbzMzM2MICQaDhMNhcrkcS0tLxGIxotEoTqcTl8tlfMfn8+FyubDb7djt9npV79jUTYiiKOzu7rKwsMDTp09Jp9O8e/fOENLS0kI8HmdtbY2VlRWi0SiXL1/G7Xbj9XqBv6Xeu3ePwcFBmpubcbvd9aresambkL29PSYmJpicnGRhYYHFxUVkWTaECIKAKIrkcjlkWWZra4v5+Xncbjcejwf4W8jExAQej4dLly7R2tqKKIrYbKcX+4UjMmbH3stMTU1x584dcrkciqIYgbWmsP8GT71MvaGCIBjP2traCIfDPHz4kOHhYZqammqGVB05NJLXrYfYbDa8Xi+KolCpVPB6vUQiEUKhEO3t7ZRKJWRZRpIknE4nsiyzublJqVSiUCiQzWbJZrPIssza2hrJZJJQKEQikTB6ymnElLr1kHQ6zaNHj9jY2GB1dZWenh5u3bpFf38//f39FAoFMpkMPp8Pv9/P6uoqX758YX19nc3NTcbGxnj79q0xDfv9fpqbm3n8+DHDw8MEAoF695ST7SE+n4+hoSFyuRzfv3+nvb2dgYEBIpEIoijidDoJhUI4nU4kSaKlpYWLFy8Si8WQZRm3200kEmFqaoqvX79SrVbZ2dlhcXGR5eVlPB7PSQ2dGurWQ6rVKuVyGVVVqVariKKIy+WqWXjtD7D7y9U0jWKxSKFQYGRkhCdPnrC1tUUul+P+/fv09fXx4MED4vH4v2rkTzjZfIi+8nQ4HEiShMPhwGaz1axC98vR/y0IAjabDYfDgcfj4cKFCwwODhIKhdA0jVQqxeTkJKlUiq2tLUqlUr2qfCh1GzKCIPzWilOSJCRJIpFIsLu7S6FQYH5+nk+fPvH582ei0SilUolr167hdDrrVe0DNNzmzul00tbWVhMvVFU1ZqVKpXKi5TecELfbTWtrq7F61fnx4weZTIZyuXyi5dd9c/e7HBaEdU7j2LXhesjPOK0z6D9GyGnlTBpuyOxn/xS9/+dJ0jBC9Eza+vo64+PjrK2t1bzv7Ozk+vXrNDU1nWg9GmbI6CnHVCrF2NgY8/PzxjtBEOju7iaRSJx4jqRhesjKygrJZJI3b96QTCbJZrMAnD9/nmg0SldXFz6f78R3vA0jZG5ujpGREZLJJN++fTOex+NxEokEkUjkVDJoDSNkc3OTiYkJdnZ20DQNSZIQRZFEIsHQ0BB+v/9U6tEwQra3t0mlUsbCTBRFPB4PXV1d9PX14fP5TqUeZyakWCySz+dZXFwkmUwyOjqKIAi4XC6cTifDw8NcuXKFmzdvEg6HkSTpyG9qmoYsy1SrVSNzr5/9HJdTEXLYKrNUKpHJZHj9+jXPnj1jY2MDQRCQJAmv18vVq1e5e/cuHR0dRu84arWqaRq5XI5CoUBbW5uRgjCnIf6JEzm5U1WVSqXC3t4e2WyWycnJA41JpVLMz88zOzvL6uoqxWKx5v3s7CySJBEKhWhubgYwTvx+RqVS4ePHj8iyzF9//YXP5yMYDNLS0sKNGzeOFZRPRIiePdva2mJ6eprnz58fyMAvLS0xNzdHoVCoOa7Qv5FOp2uOQvdn235WrqIojI+Pk8vl6O7uprm5mWAwSCQSob+//2yE5PN5Pnz4wNzcHO/fv2dzc5Pp6ekDPUSPIeb8RrFYpFqtMjMzQzqd/qWyVVVle3sbRVHY2NhAVVUGBwfp6upCFI/X1LoK0TSNfD7P6Ogos7OzvHjxgmq1+kv/X1EUFEWhUCgc2MNomnZoD9mfMtBjRrlcplKpEIlE6OzsPPaCrm5CisUiqVSKiYkJXr58STabPTBM/gn91gDUCojFYrS2thKJRGhqajpUiMPhYHh4mFgsZrzX1zH6gu44sxTUUUi5XGZhYYHp6WlmZmYol8sHkj37G6xHfj1I6vL2B01BEAiHw8TjcWKxGKFQ6FAh+jQdCoV+ux11E+J2uxkYGMDhcPDq1SuAmt/o8vIyCwsLhEIhOjs76enpobe3l0AgQCAQAA4fEq2trfh8PuNWwGHYbDbOnTtXl3bUTYgoigQCAdrb24nH4wiCYEyXAHa7nUwmQzAYpKuri97eXm7fvm2c0P0Mh8OBKIp/3lGmPiTy+TyTk5O43W5aWlqM9+vr6ySTSTo6OojH4zQ1NXHu3Lkj74HoQ+sEbhod+rG6CdEpl8vk83mcTmfN/iOfz7O8vEwgECAYDGKz2c7kQsw+TkeIfpSpb9B09FsBdrvdONA647tlpyPkD8K6634cLCEmLCEmLCEmLCEmLCEmLCEmLCEmLCEmLCEmjtr+N84fspwSVg8xYQkxYQkxYQkxYQkxYQkx8R8VmUcHI5TQRQAAAABJRU5ErkJggg==\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Show image for valid dataset\n",
        "show_image(valid_vectors[-10, :].view(28, 28));"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85
        },
        "id": "7eu6cQ2UZtHK",
        "outputId": "16e078ef-1cb7-4e2d-b629-4b4461d56cfd"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 72x72 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert train_target to 2D array for proper zipping\n",
        "\n",
        "train_target_t = tensor(train_target).unsqueeze(1)\n",
        "train_target_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdtuLw3YJJpA",
        "outputId": "b6679f5d-dde6-4e9a-e4af-ab60cd5d3a21"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([11876, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Convert valid target to 2D array\n",
        "\n",
        "valid_target_t = tensor(valid_target).unsqueeze(1)\n",
        "valid_target_t.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTp8MKtDZ172",
        "outputId": "75f2cb8c-c0f1-4b42-dc93-92373a11a30e"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1990, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Zip both values of data and target of training set into a dataset\n",
        "\n",
        "train_dset = list(zip(train_vectors, train_target))\n",
        "train_dset[0][0].shape, train_dset[0][1]\n",
        "#This will be useful when we want to use a dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QndNlp_QJJsR",
        "outputId": "ca62a17a-5030-4a56-95cd-374c0921a2be"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Zip both values of target into a dataset\n",
        "\n",
        "valid_dset = list(zip(valid_vectors, valid_target))\n",
        "valid_dset[0][0].shape, valid_dset[0][1]\n",
        "#This will be useful when we want to use a dataloader"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xnolfxgsaETH",
        "outputId": "b0bb47e4-ba61-45ac-9547-9a990c7fea2d"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784]), 0)"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Initialize Parameter\n",
        "\n",
        "Paramter refers to the weights that is used to multiply each pixel value that is represented in the picture and as a vector in train data. One more thing however about parameters is that for each weight designed, a bias should be added. Following the simple linear function equation $$ y = mx + b $$\n",
        "\n",
        "where b is the bias, the intercept.\n",
        "To do all of this, we will be defining a class but trying out the functions outside of the class. To initialize some weights, we randomly generate the values and apply the require_grads method of pytorch to tell the computer that for any function this parameters are used and the `backward propagation` of the function is called, we would need our processor to calculate the gradients of these parameters with respect to such function."
      ],
      "metadata": {
        "id": "SvlS9xD7KUty"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#init_param\n",
        "torch.seed=42\n",
        "def init_param(shape):\n",
        "  return torch.randn(shape, 1).requires_grad_(), torch.randn(1).requires_grad_()\n",
        "paramm = init_param(train_vectors.shape[1])"
      ],
      "metadata": {
        "id": "65vrb8RY8kjA"
      },
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class neural_net:\n",
        "  def __init__(self, train_vecs):\n",
        "    self.train_vecs = train_vecs #which is the training vectors\n",
        "  def initialize_params(self):\n",
        "    self.weight = torch.randn(self.train_vecs.shape[1], 1).requires_grad_()\n",
        "    self.bias = torch.randn(1).requires_grad_()\n",
        "    return self.weight, self.bias"
      ],
      "metadata": {
        "id": "ou8vvcbaJJvd"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "nnet = neural_net(train_vectors)\n",
        "wt, bi = nn.initialize_params()\n",
        "\n",
        "print(wt.shape)\n",
        "print(\" \")\n",
        "wt[:5], bi #Note the grad_fn information at the outputs"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DBTpCpBtJJzI",
        "outputId": "e609af8e-fa9f-4d43-bf16-a3297fa01404"
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([784, 1])\n",
            " \n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[0.0169],\n",
              "         [0.0803],\n",
              "         [0.7448],\n",
              "         [1.3455],\n",
              "         [0.1268]], grad_fn=<SliceBackward0>),\n",
              " tensor([1.0122], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Make Predictions\n",
        "\n",
        "Next is to use the weights to make predictions using matrix multiplication"
      ],
      "metadata": {
        "id": "S8UuCICiC6BA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function to make predictions\n",
        "\n",
        "def make_preds(xb): return xb@weights + bias"
      ],
      "metadata": {
        "id": "w43RxtMJRfy_"
      },
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Initialize the weight and bias\n",
        "weights, bias = paramm\n",
        "\n",
        "weights.shape, bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "teh3WitcSeO7",
        "outputId": "02906b1f-72f3-4691-92bf-455b59fbc969"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 1]), tensor([-0.6236], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "preds = make_preds(train_vectors)\n",
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wptc6tFaSuIk",
        "outputId": "d2b5524f-2b00-4ddc-d05a-c600cc90a2fd"
      },
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1632],\n",
              "        [ 0.9474],\n",
              "        [ 4.0635],\n",
              "        ...,\n",
              "        [12.1747],\n",
              "        [-8.7102],\n",
              "        [-3.1788]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add function make_preds to the class we are trying to build\n",
        "\n",
        "class neural_net:\n",
        "  def __init__(self, train_vecs):\n",
        "    self.train_vecs = train_vecs #which is the training vectors\n",
        "  def initialize_params(self):\n",
        "    self.weight = torch.randn(self.train_vecs.shape[1], 1).requires_grad_()\n",
        "    self.bias = torch.randn(1).requires_grad_()\n",
        "    return self.weight, self.bias\n",
        "  def make_preds(self):\n",
        "    self.raw_predictions = self.train_vecs@self.weight + self.bias\n",
        "    return self.raw_predictions"
      ],
      "metadata": {
        "id": "VdEb8XflJJ55"
      },
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test prediction method to work for class\n",
        "nets = neural_net(train_vectors)\n",
        "nets.initialize_params()\n",
        "preds_class=nets.make_preds()\n",
        "preds_class"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AqfRoBzRJJ-E",
        "outputId": "1ac9b84b-6c0c-4175-8f09-b1ae241f7481"
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-3.3724],\n",
              "        [ 8.3267],\n",
              "        [ 0.1342],\n",
              "        ...,\n",
              "        [22.3979],\n",
              "        [15.0937],\n",
              "        [18.9928]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Calculating loss functions and metrics\n",
        "\n",
        "Since these weights were randomly initiated, we expect that the answers would be also random and be meaningless especially at the first try. Because of this we will be needing a function that can help us compare our prediction against the actual target and tells us how far we are from our result. The natural choice to go to when dealing with a classifcation problem like this is to use accuracy, which measures how accurate the prediction made is. The next section leads us to `calculating loss functions and metrics`"
      ],
      "metadata": {
        "id": "qn3GtK__bdtZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accurate(pred, targets):\n",
        "  acc = (preds>0.0).float() == targets\n",
        "  return acc.float().mean()"
      ],
      "metadata": {
        "id": "i72E_JNQJKHm"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accurate(preds, train_target_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cVILptcXmrFW",
        "outputId": "b0c23202-b4f5-4570-e30f-04d627b8786b"
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4789)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function that seeks to measure accuracy, makes use that predictions that are negative(less than 0) are False(0, which represents the digit 2 in our data design) and predictions that are positive(greater than 0) are True(1, which represents our digit 6). \n",
        "\n",
        "This True or False value converted to numbers(floats) are then compared to the actual targets and we obtain a 0.544 accuracy, whic states that the model is about 54% correct (Might vary depending on the value initiated for our weights and bias by the initiating parameter). \n",
        "However, there is a slight problem with using accuracy as a loss function. One important thing when choosing a good loss function is that the function is smooth over time.\n",
        "\n",
        "In simple terms, a little change in the independent variable (The parmeters - Weight and Bias) should lead to a (little)change in  the dependent variable (The loss). This simple narrative is the principle that gradients and calculating gradients hinges upon. And calculating the gradients of the loss function(dependent variable) with respect to the parameters(weights and biases) is the principle upon which `backpropagation` hinges.\n",
        "\n",
        "In the case of accuracy, this is not so because accuracy as the loss function is either 0 or 1 and not in between, and for most part of let's say a particular weight, the accuracy will be (0 or 1, but let us say 0) 0 and whether the particular weight is increasing or decreasing, the accuracy will remain unchanged until it gets an exact value that allows it to jump from 0 to 1. This jump which is caused by a small change in the weight (for instance 0.0001, in mathematical terms, as the number tends to zero), allows the gradient to be calculated as 1/0.0001 which as the number tends to zero, so also does the gradient tend to infinity. This large jumps in the gradient of using accuracy as a loss function is not useful for stepping the weights when needed, see demonstration of the above below."
      ],
      "metadata": {
        "id": "jnPrp9Y6mJ8C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "preds"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eff6TApKJKLl",
        "outputId": "6e47a3c4-f784-4a0c-d4f6-94c7d89d2db5"
      },
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.1632],\n",
              "        [ 0.9474],\n",
              "        [ 4.0635],\n",
              "        ...,\n",
              "        [12.1747],\n",
              "        [-8.7102],\n",
              "        [-3.1788]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Accuracy before we alter a given weight\n",
        "acc1 = accurate(preds, train_target_t).item()\n",
        "acc1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nv1YE10JJKPN",
        "outputId": "a369e714-fc5f-4b32-e390-56f50c25a3cd"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4788649380207062"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#A particular weight that has not been changed yet\n",
        "weights[320]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z6PCfaijue8l",
        "outputId": "3892cf16-fc5f-403c-e6c6-29bfe5563008"
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0328], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Changing the given weight above\n",
        "\n",
        "with torch.no_grad(): weights[320] *= 1.01"
      ],
      "metadata": {
        "id": "mk6I24NWJKSq"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Weights changed and altered\n",
        "weights[320]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zsuKzaVEJKW4",
        "outputId": "8402b61e-2982-4603-a33b-21586b636663"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0331], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that a particular weight has been changed and should change the resulting predictions that should change the loss function but would not.\n",
        "\n",
        "**Note:** The with torch.no_grad() is to inform the computer not to calculated a gradient for the particular function performed on the parameter."
      ],
      "metadata": {
        "id": "cF08yCvUvH-H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions1 = make_preds(train_vectors)\n",
        "acc2 = accurate(predictions1, train_target_t).item()\n",
        "acc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0mqmJWRJKcO",
        "outputId": "20f90502-703d-4a9c-ca2e-1eeac2854bed"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.4788649380207062"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test to see acc1 and acc2 are same -- Result: True\n",
        "acc1 == acc2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0VqVREaNZhZv",
        "outputId": "4839e353-2f8a-400c-d5f0-ccf84b28974d"
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "####Loss function, Gradient Descent and Sigmoid Function.\n",
        "\n",
        "From what we see above, we know already that accuracy would not serve as a good loss function because for most part of a given weight, the `gradient of the loss function` with respect to (w.r.t) a particular weight will be zero and at the peak of change, it will be infinity. This will not be useful to step our weights.\n",
        "\n",
        "In order to deal with this, imagine the following:\n",
        "1. Our prediction is between 0 and 1.\n",
        "2. For any confident prediction in the right direction, our model is not penalized so much, but for any confident prediction in the wrong direection, our model is largely penalized. \n",
        "\n",
        "It so happens that these two conditions can be implemented through pytorch.\n",
        "The first condition can be implemented through a function called sigmoid. Sigmoid fits any values from negative infinity to positive infinity to be in between 0 and 1. The formula for this is given as:\n",
        "\n",
        "$$ S(x) =  \\frac{\\mathrm{1} }{\\mathrm{1} + e^{-x} }  $$ \n",
        "\n",
        "The second condition works the following ways, since our model can now make a prediction between 0 and 1 with any float in between, we can the penalize any confident that goes in the wrong direction\n",
        "\n",
        "For example, if our model makes a prediction as 0 and the actual is 0, the penalty for such prediction should be 0 but if the actual is 1, the penalty for such confident misinterpretation should 1.0. If it is 0.6 for instance and the actual target is 1.0, the penalty should be 0.4 and so on. . .\n",
        "\n",
        "This means a large loss means a poor model and a small loss means a great model with small penalty attched to it."
      ],
      "metadata": {
        "id": "1VGNic2nwJPJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "plot_function(torch.sigmoid,\n",
        "              title=\"Sigmoid function plot\",\n",
        "              tx=\"x\", ty=\"Sigmoid\",\n",
        "              min=-4, max=4);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 302
        },
        "id": "PtYouw1BJKhM",
        "outputId": "d0870081-0383-4c4b-86ac-09ef116006e7"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Redefine class once again, and add loss function\n",
        "class neural_net:\n",
        "  def __init__(self, train_vecs, target_vecs):\n",
        "    self.train_vecs = train_vecs #which is the training vectors\n",
        "    self.target_vecs = target_vecs\n",
        "  def initialize_params(self):\n",
        "    self.weight = torch.randn(self.train_vecs.shape[1], 1).requires_grad_()\n",
        "    self.bias = torch.randn(1).requires_grad_()\n",
        "    return self.weight, self.bias\n",
        "  def make_preds(self):\n",
        "    self.initialize_params()\n",
        "    self.raw_predictions = self.train_vecs@self.weight + self.bias\n",
        "    return self.raw_predictions\n",
        "  def loss_func(self):\n",
        "    self.make_preds()\n",
        "    self.predictions = self.raw_predictions.sigmoid()\n",
        "    loss=torch.where(self.target_vecs==1, 1-self.predictions, self.predictions).mean()\n",
        "    return loss"
      ],
      "metadata": {
        "id": "p8aUc7puJKkm"
      },
      "execution_count": 232,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "neural_net(train_vectors, train_target_t).loss_func()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "id": "1YbEDJm3JKo9",
        "outputId": "2e7b5fdb-4eaa-4da1-e3e7-84d03e4b398c"
      },
      "execution_count": 233,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.3141, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 233
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function outside the class for implementation\n",
        "def loss_func(pred, target):\n",
        "  pred = pred.sigmoid()    #1st condition, sigmoid function\n",
        "  return torch.where(target==1, 1-pred, pred).mean()   #Second condition\n",
        "sig_loss1 = loss_func(predictions1, train_target_t).item()\n",
        "sig_loss1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TMFqxFutJKsr",
        "outputId": "2319c8aa-2015-4f80-f9c2-ff7cddf1d7ae"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.523318350315094"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Lets us change something in the weights as above to spot any change\n",
        "weights[320]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NUNmqQMo7-to",
        "outputId": "4d04dfe0-7e54-40c3-d477-229ec210ce1d"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0331], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "P:S - There is a difference between the class output on the loss function largely due to multiple calling of some random parameters."
      ],
      "metadata": {
        "id": "aI-NieJ69grv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#CAlter weights\n",
        "with torch.no_grad(): weights[320] *= 0.991"
      ],
      "metadata": {
        "id": "JtePyolrBuCa"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#ltered weigghts\n",
        "weights[320]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYWOVZNzc2Rk",
        "outputId": "20503e03-dfc0-4636-f730-b36ebe0056d1"
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0328], grad_fn=<SelectBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions2 = make_preds(train_vectors)\n",
        "sig_loss2 = loss_func(predictions2, train_target_t)\n",
        "sig_loss2.item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zYtGBKJSJKyi",
        "outputId": "4ddc81d5-3a6a-4927-a29f-b1f7389bc321"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.5233126878738403"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#The loss has responed to the same level of change as with previous accuracy loss function\n",
        "#Test if the losses are the same\n",
        "(sig_loss1 == sig_loss2).item()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EZOgfTggdsiL",
        "outputId": "aa917275-8ce1-4f5f-a883-dca79f7853d1"
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "False"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Yeah! As predicted, there is a difference in the loss function result when the parameter slightly changed. The loss function however is a mathematical formula that is useful for stepping the weights in neural networks but not for really understanding how well the model is making a good prediction. Thus we will be adding the accurate function that returns how accurate the prediction we are making is."
      ],
      "metadata": {
        "id": "EBtXa5xkCxtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def accurate(pred, targets, threshold=0.5):\n",
        "  acc = (preds>threshold).float() == targets\n",
        "  return acc.float().mean()"
      ],
      "metadata": {
        "id": "wz5SXLGAjFMe"
      },
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accurate(predictions2, train_target_t)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2lZ8JCDjGNF",
        "outputId": "7efa7964-9f2b-4e13-8fcb-5e13655e236f"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4750)"
            ]
          },
          "metadata": {},
          "execution_count": 81
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Where the magic happens.** We can obtain gradient of the loss function w.r.t each parameter. This obtained information used to step the weights in the direction to minimize the loss function. For better understanding of this, you can assume that loss function is a quadratic function with a single paramter x, in DL we will need a value of x that minimizes as much as possible the loss function on the parabolic curve. The mathematical and computer way to do this is to determine the gradient of the function at point x and use that to step the weights in the direction of the gradient while avoiding overshooting the minima."
      ],
      "metadata": {
        "id": "QpXeZU_AF7RT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Call loss.backwards()\n",
        "sig_loss2.backward()\n",
        "#This method calls populates the weights and bias with the\n",
        "#.grad(gradients) attribute, remember `.requires_grad_()`?"
      ],
      "metadata": {
        "id": "3_K-MFFpF2Vz"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "weights.grad[200:220, :]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "55dH7OUcFJ3q",
        "outputId": "477e4931-353f-46da-f701-b74fab9233ea"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0003],\n",
              "        [ 0.0008],\n",
              "        [ 0.0017],\n",
              "        [ 0.0026],\n",
              "        [ 0.0031],\n",
              "        [ 0.0037],\n",
              "        [ 0.0039],\n",
              "        [ 0.0024],\n",
              "        [-0.0004],\n",
              "        [-0.0036],\n",
              "        [-0.0047],\n",
              "        [-0.0022],\n",
              "        [ 0.0027],\n",
              "        [ 0.0076],\n",
              "        [ 0.0097],\n",
              "        [ 0.0087],\n",
              "        [ 0.0065],\n",
              "        [ 0.0043],\n",
              "        [ 0.0019],\n",
              "        [ 0.0004]])"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rB-dnZS1fiVh",
        "outputId": "69f691c9-62c8-4047-fbb6-778d408c9dc0"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.0039])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weights.grad.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_q_AL8RTgaTd",
        "outputId": "f7f703e3-4921-42ed-b76f-2f699ad13579"
      },
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([784, 1])"
            ]
          },
          "metadata": {},
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Add accuracy function to class\n",
        "class neural_net:\n",
        "  def __init__(self, train_vecs, target_vecs):\n",
        "    self.train_vecs = train_vecs #which is the training vectors\n",
        "    self.target_vecs = target_vecs\n",
        "  def initialize_params(self):\n",
        "    self.weight = torch.randn(self.train_vecs.shape[1], 1).requires_grad_()\n",
        "    self.bias = torch.randn(1).requires_grad_()\n",
        "    return self.weight, self.bias\n",
        "  def make_preds(self):\n",
        "    self.initialize_params()\n",
        "    self.raw_predictions = self.train_vecs@self.weight + self.bias\n",
        "    return self.raw_predictions\n",
        "  def loss_func(self):\n",
        "    self.make_preds()\n",
        "    self.predictions = self.raw_predictions.sigmoid()\n",
        "    loss=torch.where(self.target_vecs==1, 1-self.predictions, self.predictions).mean()\n",
        "    return loss\n",
        "  def accurate(self, threshold=0.5):\n",
        "    self.make_preds()\n",
        "    acc_pred = self.raw_predictions.sigmoid()\n",
        "    acc_= (acc_pred>threshold).float() == self.target_vecs\n",
        "    return acc_.float().mean()"
      ],
      "metadata": {
        "id": "QfHEx0FAjGVg"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_net = neural_net(train_vectors, train_target_t)\n",
        "test_net.accurate()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s-JpSUkIjGgn",
        "outputId": "97ea5666-5fe3-40f8-e64a-c1e8304540c3"
      },
      "execution_count": 88,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4761)"
            ]
          },
          "metadata": {},
          "execution_count": 88
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that the weights.grad attribute gives an output of the shape of the number of parameters that that we insantiated. i.e. every weight has a gradient value w.r.t the loss function. This gradient essentially gives us an information, which is the direction of the function to minimize the loss. We will be considering this in the next section but before that, we can see how this basically would work. Since the gradient shows the change that would happen(change in loss function) if there is a unit change in x and not the unit change, we must gradually step it down, so that we don't fly over the minima and bounce around. We also would like to choose a factor that would multiply the change(gradient) such that we arrive faster at a minima. This deciding factor is often left in the hands of DL practictioners to determine (as a hyperparameter). For this, we would just choose 0.0001. This factor is called the learning rate(lr)"
      ],
      "metadata": {
        "id": "JhCjAZzLg4Lk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "lr = 0.0001\n",
        "epochs = 4\n",
        "loss = tensor(np.nan)\n",
        "for i in range(epochs):\n",
        "  print(\"Mean Parameter{}\".format(i+1), weights.mean().item()), print(\"Bias{}\".format(i+1), bias.item()), print(\"loss{}\".format(i+1), loss.item()), print(\" \"),\n",
        "  pred = make_preds(train_vectors)\n",
        "  loss = loss_func(pred, train_target_t)\n",
        "  loss.backward()\n",
        "  with torch.no_grad():\n",
        "    weights -= lr*weights.grad\n",
        "    weights.grad.zero_(); \n",
        "  with torch.no_grad():\n",
        "    bias -= lr*bias.grad\n",
        "    bias.grad.zero_();\n",
        "  #Using torch.no_grad(), helps us to calculate the the param IN PLACE but also asking that the gradient is not tracked.\n",
        "  #To avoid gradient accumulation, we use the .grad.zero_() over each epoch"
      ],
      "metadata": {
        "id": "sXjGIYjjlRxI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3a8313fb-d210-4f58-fff8-d36fd332652b"
      },
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean Parameter1 0.01053717453032732\n",
            "Bias1 -0.6236460208892822\n",
            "loss1 nan\n",
            " \n",
            "Mean Parameter2 0.010537194088101387\n",
            "Bias2 -0.6236456036567688\n",
            "loss2 0.5233010053634644\n",
            " \n",
            "Mean Parameter3 0.01053721085190773\n",
            "Bias3 -0.6236451864242554\n",
            "loss3 0.5232996940612793\n",
            " \n",
            "Mean Parameter4 0.010537231341004372\n",
            "Bias4 -0.6236447691917419\n",
            "loss4 0.5232986211776733\n",
            " \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We see that our loss is reducing as our weights and biases are being adjusted by their gradients (the direction) and learning rate (magnitude).\n",
        "\n",
        "**Note to future self** In using pytorch and during initiating and updating the weights parameter, take note to use inplace operation `(i.e. a -= b)` and not out of place operators like `a = a + b`. For more information, check out this [link](https://medium.com/@mrityu.jha/understanding-the-grad-of-autograd-fc8d266fd6cf)"
      ],
      "metadata": {
        "id": "jzLqBmzd0udC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Stepping Weights: Stochastic Gradient Descent and Minibatches. (Combining all the steps together)\n",
        "\n",
        "We already have a sense of how stochasstic gradient descent works and how it is used to step down our respective weights. In deep learning however, weights are not adjusted epoch by epoch (number of trainings). They are adjusted in minibatches.\n",
        "\n",
        "While our dataset that we are using is 28 by 28 greyscale image, we often deal with higher dimension of images (3-channel images like RGB images) with higher sizes that compressing it to say 28by28 image will make it loose the image distinguishing features. For instance, in the model I deployed to hugging face that identified a zebra from an elephant, had images that were pixel sizes greater than 300 and it was colured (3 dimensiions). This means that our image training vector will be more complicated than this and subsequently the neural net that we create.\n",
        "\n",
        "In order to solve this complexity (time) and some other advantages that I will highlight, data(for instance images) are passed in through the model in minibatches. `Batch size` refers to the number of data points that you want to use at a particular time through the model. \n",
        "\n",
        "Take for instance, our model will be using 6,000 images for training and during training, we assign that we will be training the model for 5 epochs and batch size of 500 (Although I doubt DL practictioners will use that number or such round number, you might rather find something like 256 or 512, I don't know why yet). So, what happens is that during epoch 1, we choose 500 data points from the pool of the 6,000 datapoints, make predictions, calculate loss function and metrics, adjust the weights, reset the gradients and go on to another set of 500 datapoints. We only finish epoch 1  when the 6,000 datapoints have been used to train the model(That will be about 12 times during epoch 1). We do this for epoch 2, 3, 4 and 5. And the result obtained is recorded.\n",
        "\n",
        "Note that in our outputs, we will only see one loss and metric and other outputs values for each epoch and not for each minibatch. Usually, the loss function and metrics are averaged accross the mini-batches in one epoch.\n",
        "\n",
        "In choosing a batch size, a hyperparameter also, when you choose a low batch size(bs) e.g 1, which means the whole dataset per training, then the following happens;\n",
        "1. Your training time is slow and more complicated\n",
        "2. You get to change your parameters only by the number of epochs you have chosen, since you have just 1 batch size per epoch. This is the reason, coneventionally you have to double your learning rate(lr) when you double your batch size (bs). A small batch size means a lot of times to change your parameters,(Although there is a great tendency to get stuck in a local minima), so using a small lr will gradually allow you get to your minima but when you increase the bs, you have lesser number of trainings (& noise trainings) to perform and that small lr might not get you to the minima, so incresing the lr will compensate for the reduced number of training. Read this [article ](https://medium.com/geekculture/how-does-batch-size-impact-your-model-learning-2dd34d9fb1fa) if you want to know more \n",
        "3. Your metrics, gradients and loss are more stable accross each training epoch. In an epoch, you have just one value for your outputs, this means your standard deviation accross your output(s) is null(zero). If you have two bs for instance, the mean of two \"not equal\" outputs are averaged and displayed, since the datapoints for each mini batch is different, so will be the losses and the gradients.\n",
        "\n",
        "However, when you choose a high batch size(bs) e.g 6000, which means one single data point per training, then the following happens;\n",
        "\n",
        "1. If you don't get a GPU `out of memory error`, more like CUDA `out of memory error`, then the process can be parallelized on GPUs and training time subsequently shorter.\n",
        "2. You get to change your parameters 6000 times per epoch, which means you get to adjust your parameters 6,000 * 5 times (30,000 times), where 5 is the number of epochs that you have chosen.\n",
        "3. Number 2 obviously has a downside to it which is that our gradients are very volatile and a high possibility of divergence from the loss minima possible. Also our outputs will be quite unstable, with 6000 outputs being averaged per epochs, which suggests most likely high standard deviation as different images will have different different features. This results into an example of overfitting, with high variance, because our model becomes too sensitive to each data point and data distribution of our data points, which makes the model loose it's generalization ability.\n",
        "\n",
        "In order to use minibatches, I will be using fastai's DataLoader class and the datasets that I created initially, I will also create te valid dataset."
      ],
      "metadata": {
        "id": "pM9iHS8eDKCk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#hyperparamaters instantiation\n",
        "bs = 256"
      ],
      "metadata": {
        "id": "eO-BBSn5tcbi"
      },
      "execution_count": 99,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dl = DataLoader(train_dset, batch_size=bs)\n",
        "xb, yb = first(train_dl)\n",
        "xb.shape, yb.shape"
      ],
      "metadata": {
        "id": "-VGCz35Lo51U",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6079e5c-6c29-4a3d-e22d-bbef3f5f0766"
      },
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256]))"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Put valid dset into data loader too\n",
        "valid_dl = DataLoader(valid_dset, batch_size=bs)\n",
        "xv, yv = first(valid_dl)\n",
        "xv.shape, yv.shape"
      ],
      "metadata": {
        "id": "PRY05SDipSeP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dee3d36-2d07-4ffd-c695-cfad4d916a65"
      },
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([256, 784]), torch.Size([256]))"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us define a test_batch from the training set that we will use to try out each step we might want to try\n",
        "batch_x = train_vectors[:7]\n",
        "batch_y = train_target_t[:7]"
      ],
      "metadata": {
        "id": "k7P8CM75t4Hv"
      },
      "execution_count": 103,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#step 1 -- initiate parameter\n",
        "weights, bias = init_param(xb.shape[1])\n",
        "weights.shape, bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CUI9BL6Jwjz2",
        "outputId": "daaa20a3-aa7b-4989-bf2f-88a45dff1cb5"
      },
      "execution_count": 140,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([784, 1]), tensor([-1.1861], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 140
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#make predictions -- using raw weights and bias before trying function to see that our result is working well\n",
        "batch_x@weights + bias"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0m0CLi5Dw-ZA",
        "outputId": "b250d219-55c7-4081-eb70-35a996cb94d4"
      },
      "execution_count": 109,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11.5014],\n",
              "        [-1.6144],\n",
              "        [-4.9224],\n",
              "        [ 4.4609],\n",
              "        [-8.7745],\n",
              "        [-6.2469],\n",
              "        [ 9.8588]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 109
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Try function that we created\n",
        "make_preds(batch_x) #Step 2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YSM5z8JTw_A5",
        "outputId": "e3470a23-1097-45f7-c5d3-c24cd08f1e80"
      },
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[11.5014],\n",
              "        [-1.6144],\n",
              "        [-4.9224],\n",
              "        [ 4.4609],\n",
              "        [-8.7745],\n",
              "        [-6.2469],\n",
              "        [ 9.8588]], grad_fn=<AddBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are right on track!"
      ],
      "metadata": {
        "id": "6R3bLq1xyUCz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Loss function that takes raw predictions and obtains a result\n",
        "loss_func(make_preds(batch_x), batch_y) #Step 3"
      ],
      "metadata": {
        "id": "jjGRsJpCoc_X",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "249802b6-7a9a-49f3-b329-6c54c22bb86b"
      },
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor(0.4520, grad_fn=<MeanBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Step 4: calculate gradients\n",
        "def calc_grad(x, y, model):\n",
        "  pred = model(x)\n",
        "  loss = loss_func(pred, y)\n",
        "  #calcluate grad with loss.backward()\n",
        "  loss.backward()\n",
        "#Function combines step 1 to step 4"
      ],
      "metadata": {
        "id": "ZMI8fduZz7qU"
      },
      "execution_count": 191,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on batch_x\n",
        "calc_grad(batch_x, batch_y, make_preds)\n",
        "\n",
        "weights.grad.mean(), bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mRIpEhxH1Otm",
        "outputId": "c183a2c2-e3c0-4096-964f-163df54762cf"
      },
      "execution_count": 115,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0034), tensor([0.0454]))"
            ]
          },
          "metadata": {},
          "execution_count": 115
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#second call on calc_grad(loss.backward)\n",
        "calc_grad(batch_x, batch_y, make_preds)\n",
        "\n",
        "weights.grad.mean(), bias.grad"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MzXReB2L3MDm",
        "outputId": "839d2ad4-0ad0-45d1-cf6b-f3d1041c4600"
      },
      "execution_count": 116,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0052), tensor([0.0682]))"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Remember when I talked about using `weights.grad.zero_()` to zero our gradients, it turns out that when we call loss.backward as in the calc_grad function that we used above, the gradient accumulates in the .grad attribute, thus when we are done stepping our weights, it is important that we that we zero our gradients."
      ],
      "metadata": {
        "id": "WMpa4nn42H9f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#zero grad before calling loss.backward\n",
        "weights.grad.zero_()\n",
        "bias.grad.zero_()\n",
        "\n",
        "#Print weight and bias grad\n",
        "print(\"Result of zeroing the grads\")\n",
        "print(weights.grad.mean(), bias.grad)\n",
        "print(\" \")\n",
        "\n",
        "#Calc calc_grad\n",
        "calc_grad(batch_x, batch_y, make_preds)\n",
        "\n",
        "#print the grad\n",
        "print(\"Gradients without accumulation\")\n",
        "weights.grad.mean(), bias.grad"
      ],
      "metadata": {
        "id": "tWMDyiq_nUXu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6fc30e4-4ab6-4ada-f6af-320823993f3b"
      },
      "execution_count": 121,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Result of zeroing the grads\n",
            "tensor(0.) tensor([0.])\n",
            " \n",
            "Gradients without accumulation\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0017), tensor([0.0227]))"
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "While the loss function returns a smooth function that can be used to iterate over our model and improve the model, the best way to examine the model is to view a metric that is understandable by humans, for classification, it is accuracy, that tells us how well our model is performing. And this is performed over the validation set."
      ],
      "metadata": {
        "id": "q4D5l8RMyP_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function that takes the raw predictions and compares it against a \n",
        "#threshold to determine accuracy\n",
        "\n",
        "def accurate(pred, targets, threshold=0.5):\n",
        "  preds = pred.sigmoid()\n",
        "  acc = (preds>threshold).float() == targets\n",
        "  return acc.float().mean()"
      ],
      "metadata": {
        "id": "F3JiZjhOFl0_"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "This function is going to be able to calculate the accuracy for each batch of validation set when testing each intermediate model(i.e. final model at the end of each epoch). To calculate the  average accuracy accross the validation set for each epoch, we will need another function that uses the accurate function above."
      ],
      "metadata": {
        "id": "jP55Qk285Rkp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def validate_epoch(model):\n",
        "  batches_accuracy = torch.stack([accurate((model(xb)), yb) for xb, yb in valid_dl])\n",
        "  return round(batches_accuracy.mean().item(), 4)"
      ],
      "metadata": {
        "id": "avCGB7oh_A0_"
      },
      "execution_count": 134,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = weights, bias\n",
        "lr = 1."
      ],
      "metadata": {
        "id": "vcoysSXd76E0"
      },
      "execution_count": 145,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Define function that trains model in one epoch (i.e.) step weights per minibatch in a single epoch\n",
        "def train_epoch(model, lr, params):\n",
        "  for xb, yb in train_dl:\n",
        "    calc_grad(xb, yb, model)\n",
        "    #Update weights and biases\n",
        "    for p in params:\n",
        "      with torch.no_grad():\n",
        "        p -= p.grad * lr\n",
        "        p.grad.zero_()"
      ],
      "metadata": {
        "id": "7HJnheuh6JKv"
      },
      "execution_count": 155,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Train epoch and validate epoch in a single epoch\n",
        "\n",
        "train_epoch(make_preds, lr=lr, params=params)\n",
        "print(validate_epoch(make_preds))"
      ],
      "metadata": {
        "id": "GvBTPUUYGskf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "219ec39c-8796-480c-e453-3eba09a03901"
      },
      "execution_count": 146,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9007\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us repreat this for a couple of times (number of epochs)\n",
        "\n",
        "for i in range(10):\n",
        "  train_epoch(make_preds, lr=lr, params=params)\n",
        "  print(validate_epoch(make_preds), end=\" \")"
      ],
      "metadata": {
        "id": "DRHk4VzK3S04",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79391b12-dc9f-4094-b1e9-12312f312c69"
      },
      "execution_count": 147,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9012 0.9022 0.9022 0.9026 0.9026 0.9026 0.9031 0.9031 0.9031 0.9031 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us repreat this for a couple of times more (number of epochs)\n",
        "\n",
        "for i in range(10):\n",
        "  train_epoch(make_preds, lr=lr, params=params)\n",
        "  print(validate_epoch(make_preds), end=\" \")"
      ],
      "metadata": {
        "id": "5FQNL6GbxaOq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ed5fcf58-0374-43ff-aab2-9d77ee65552c"
      },
      "execution_count": 148,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9031 0.9043 0.9049 0.9049 0.9049 0.9049 0.9054 0.9054 0.9054 0.9054 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us repreat this for a couple of times more (number of epochs)\n",
        "\n",
        "for i in range(10):\n",
        "  train_epoch(make_preds, lr=lr, params=params)\n",
        "  print(validate_epoch(make_preds), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7qCr6dJbM_lc",
        "outputId": "ad62b54e-70d9-42d8-8133-f7f40b029652"
      },
      "execution_count": 149,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9054 0.9059 0.9059 0.9063 0.9063 0.9063 0.9063 0.9063 0.9063 0.9068 "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us repreat this for a couple of times more (number of epochs) -- multiple reuns\n",
        "\n",
        "for i in range(20):\n",
        "  train_epoch(make_preds, lr=lr, params=params)\n",
        "  print(validate_epoch(make_preds), end=\" \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dhm30jyVBhQ7",
        "outputId": "f230f156-cb69-41fb-b9c8-930ba5ff8846"
      },
      "execution_count": 163,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9325 0.9325 0.9325 0.9325 0.9325 0.9325 0.9325 0.933 0.933 0.9335 0.9335 0.9335 0.9335 0.9335 0.9335 0.934 0.934 0.934 0.934 0.934 "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "How do we know when to stop? We stop mostly on two basis, time constraints and before the validation metrics begins to get worse. For instance, it looks as if my current model cannot perform better than 0.9651 (which is 96.5%) and even dropped to 0.9647.\n",
        "(This has changed due to certain reruns and random initiation)\n",
        "\n",
        "And that is the basic idea behind how one deep learning layer. But using fastai already made class and pytorch classes to make a more complex kind of model. A \"deeper\" layer."
      ],
      "metadata": {
        "id": "cRWLICMENAaE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### The nn.linear class\n",
        "\n",
        "This class can perform step 1 and step 2 of our processes together, i.e. initiating parameters and using the parameters to make prdictions.\n"
      ],
      "metadata": {
        "id": "J32qhFf5KWJG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn.Linear(28*28, 1)"
      ],
      "metadata": {
        "id": "otIDQLecwUQU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1795f28d-bafa-4730-fb95-1bd0f607365c"
      },
      "execution_count": 173,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=784, out_features=1, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 173
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linear_model = nn.Linear(28*28, 1)"
      ],
      "metadata": {
        "id": "CicVsVqh3mcc"
      },
      "execution_count": 174,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#This class has parameters class that prints both the weights and bias together\n",
        "\n",
        "weights, bias = linear_model.parameters()\n",
        "weights.shape, bias"
      ],
      "metadata": {
        "id": "ZKNDyqWRlR6B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32ce1b09-2845-4a5c-fd74-bffeab951ecd"
      },
      "execution_count": 175,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 784]), Parameter containing:\n",
              " tensor([0.0086], requires_grad=True))"
            ]
          },
          "metadata": {},
          "execution_count": 175
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Test on batch_x\n",
        "linear_model(batch_x)"
      ],
      "metadata": {
        "id": "3EgqHd6BJK2v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "77fef6d0-dfd2-4094-f467-ff0414b2f781"
      },
      "execution_count": 182,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1530],\n",
              "        [ 0.0823],\n",
              "        [-0.0448],\n",
              "        [ 0.1741],\n",
              "        [-0.3034],\n",
              "        [-0.0041],\n",
              "        [-0.1536]], grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 182
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Optimizer Class\n",
        "\n",
        "It turns out that stepping down weights (paramters) with their respective gradients can also be automated by a class called `SGD`, (mathematically known as Stochastic gradient descent) by giving it the parameters and the learning rate."
      ],
      "metadata": {
        "id": "eJqNd1C4QQhS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = SGD(linear_model.parameters(), lr)"
      ],
      "metadata": {
        "id": "lGHOKscHJK7V"
      },
      "execution_count": 185,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us redefine training an epoch\n",
        "def train_epoch(model):\n",
        "  for xb, yb in train_dl:\n",
        "    calc_grad(xb, yb, model) #remember this performs from step 1 to calculate gradients\n",
        "    opt.step()\n",
        "    opt.zero_grad()"
      ],
      "metadata": {
        "id": "sPgYz9D0JK-F"
      },
      "execution_count": 189,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Let us train a single epoch and calculate the validate_epoch\n",
        "train_epoch(linear_model)\n",
        "print(validate_epoch(linear_model))"
      ],
      "metadata": {
        "id": "31BKzM6bJLAx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19fcf2d8-1b9b-4ab9-e879-6d321ea05e31"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5039\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Define train model that train model for a number of epochs\n",
        "\n",
        "def train_model(model, epochs):\n",
        "  for _ in range(epochs):\n",
        "    train_epoch(model)\n",
        "    print(validate_epoch(model))"
      ],
      "metadata": {
        "id": "XjkOpGDtJLDV"
      },
      "execution_count": 194,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_model(linear_model, 20)"
      ],
      "metadata": {
        "id": "5i09giqaJLJv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "01309d84-d16e-4767-8984-cf828cc9144b"
      },
      "execution_count": 195,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.5039\n",
            "0.4995\n",
            "0.583\n",
            "0.7208\n",
            "0.8127\n",
            "0.8645\n",
            "0.8885\n",
            "0.907\n",
            "0.9182\n",
            "0.9261\n",
            "0.9334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train for some more time\n",
        "train_model(linear_model, 4)"
      ],
      "metadata": {
        "id": "FBiljuFHJLM9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb16091c-cb43-4f95-c179-57ce811cf07f"
      },
      "execution_count": 196,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9373\n",
            "0.9427\n",
            "0.9481\n",
            "0.951\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Train for some more time\n",
        "train_model(linear_model, 10)"
      ],
      "metadata": {
        "id": "ImD7eWx9JLPZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fb81218-897f-40ef-c8ff-92172adeac69"
      },
      "execution_count": 197,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.9529\n",
            "0.9544\n",
            "0.9559\n",
            "0.9578\n",
            "0.9593\n",
            "0.9602\n",
            "0.9602\n",
            "0.9617\n",
            "0.9622\n",
            "0.9627\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "This classes and ready made class initiation can thus be used with fastai `Learner` Class"
      ],
      "metadata": {
        "id": "JNcWAZ9hXASH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dls = DataLoaders(train_dl, valid_dl)"
      ],
      "metadata": {
        "id": "vU0h_DTLZUQp"
      },
      "execution_count": 203,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, nn.Linear(28*28, 1), loss_func=loss_func,\n",
        "        opt_func=SGD metrics=accurate)"
      ],
      "metadata": {
        "id": "3LQpXb3zW-3s"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(20, lr)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "id": "ilb0KK2IZq0X",
        "outputId": "d8a9a983-1faf-42fd-82ab-b221f9e3ca34"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accurate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.619782</td>\n",
              "      <td>0.479820</td>\n",
              "      <td>0.518593</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.368863</td>\n",
              "      <td>0.483677</td>\n",
              "      <td>0.485427</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.168681</td>\n",
              "      <td>0.373582</td>\n",
              "      <td>0.600597</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.088863</td>\n",
              "      <td>0.269475</td>\n",
              "      <td>0.734328</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.055938</td>\n",
              "      <td>0.190396</td>\n",
              "      <td>0.824372</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.041622</td>\n",
              "      <td>0.147260</td>\n",
              "      <td>0.871106</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.035190</td>\n",
              "      <td>0.122131</td>\n",
              "      <td>0.891237</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.032148</td>\n",
              "      <td>0.105664</td>\n",
              "      <td>0.906313</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.030580</td>\n",
              "      <td>0.094019</td>\n",
              "      <td>0.916363</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.029632</td>\n",
              "      <td>0.085311</td>\n",
              "      <td>0.923932</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.028945</td>\n",
              "      <td>0.078517</td>\n",
              "      <td>0.932475</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.028384</td>\n",
              "      <td>0.073044</td>\n",
              "      <td>0.937500</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.027906</td>\n",
              "      <td>0.068530</td>\n",
              "      <td>0.943028</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.027495</td>\n",
              "      <td>0.064742</td>\n",
              "      <td>0.946545</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.027138</td>\n",
              "      <td>0.061517</td>\n",
              "      <td>0.950063</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.026827</td>\n",
              "      <td>0.058740</td>\n",
              "      <td>0.952575</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.026551</td>\n",
              "      <td>0.056323</td>\n",
              "      <td>0.954083</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.026300</td>\n",
              "      <td>0.054199</td>\n",
              "      <td>0.955057</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.026069</td>\n",
              "      <td>0.052318</td>\n",
              "      <td>0.956564</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.025852</td>\n",
              "      <td>0.050642</td>\n",
              "      <td>0.958574</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "So a basic idea is that parameters instantiation(it lies in architecture instantiation) and parameter control (i.e. calculating/instantiating gradients(not loss) i.e. param.grad, stepping the parameters by its gradients, zeroing the gradients and using them to make raw predictions) can all be fully automated, whereas the loss function(that is used to calculate the gradients), the metric and some other information can be less automated and depend on our choice.\n",
        "\n",
        "Note: Fully automated does not mean it can not be altered, just means that it can be best left as a low level process."
      ],
      "metadata": {
        "id": "W5yCpKwZX6qj"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training Deeper Layers\n",
        "\n",
        "We already know that the model making the prediction is a simple linear equation (in case of make_preds and linear_model). They are both matrix multiplication that uses the simple linear equation of:\n",
        "\n",
        "$$ y = mx_1 + b $$\n",
        "\n",
        "If we add more layers, say\n",
        "$$ y = mx_2 + b $$\n",
        "\n",
        " Where $x_2$ is the output from layer 1, the final result that we will obtain turns out to still be a linear equation of some sort (that will have used only $x_1$). In order to make each layer perform a better work and sort of independednt work, the equation needs to be disjointed, so that each layer can contribute in significant ways to the model. From this problem came the solution called `Rectified Linear Units` a.k.a ReLU.\n",
        "\n",
        " What ReLu does is very simple. It takes a value and if the value is less than 0, it converts it to 0. So in a matrix output for instance all negative numbers are converted to 0. This applied to all matrix output except for the final output."
      ],
      "metadata": {
        "id": "kkaFtQYmWbaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#See the result of y\n",
        "y = torch.randn(10)\n",
        "y"
      ],
      "metadata": {
        "id": "0QRTQgyEJLU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "107afcba-b778-41b3-f1b3-4651ff6b1534"
      },
      "execution_count": 218,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([-0.5728,  0.6545,  0.3371,  1.3475,  0.0863,  0.8933,  1.1834,  0.6913, -0.7166,  0.3890])"
            ]
          },
          "metadata": {},
          "execution_count": 218
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Apply ReLu to y\n",
        "F.relu(y)"
      ],
      "metadata": {
        "id": "lz5B8heDJLXx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3fae7039-8e8d-4345-c33f-365f78e04a3b"
      },
      "execution_count": 219,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.0000, 0.6545, 0.3371, 1.3475, 0.0863, 0.8933, 1.1834, 0.6913, 0.0000, 0.3890])"
            ]
          },
          "metadata": {},
          "execution_count": 219
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Develop a three layer neural net architecture\n",
        "\n",
        "simple_net = nn.Sequential(\n",
        "    nn.Linear(28*28, 40),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(40, 20),\n",
        "    nn.ReLU(),\n",
        "    nn.Linear(20, 1)\n",
        ")"
      ],
      "metadata": {
        "id": "GfViIuhBJLa3"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn = Learner(dls, simple_net, opt_func=SGD, loss_func=loss_func, metrics=accurate)"
      ],
      "metadata": {
        "id": "JS3zHpwiJLd6"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "learn.fit(20, lr)"
      ],
      "metadata": {
        "id": "M6XfzL9PJLhB",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 676
        },
        "outputId": "8b1617a5-eb4d-4da4-f6e5-6f941951846d"
      },
      "execution_count": 225,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "<style>\n",
              "    /* Turns off some styling */\n",
              "    progress {\n",
              "        /* gets rid of default border in Firefox and Opera. */\n",
              "        border: none;\n",
              "        /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "        background-size: auto;\n",
              "    }\n",
              "    progress:not([value]), progress:not([value])::-webkit-progress-bar {\n",
              "        background: repeating-linear-gradient(45deg, #7e7e7e, #7e7e7e 10px, #5c5c5c 10px, #5c5c5c 20px);\n",
              "    }\n",
              "    .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "        background: #F44336;\n",
              "    }\n",
              "</style>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accurate</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.445198</td>\n",
              "      <td>0.516468</td>\n",
              "      <td>0.481407</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.266118</td>\n",
              "      <td>0.503168</td>\n",
              "      <td>0.485427</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.135306</td>\n",
              "      <td>0.350189</td>\n",
              "      <td>0.650879</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.071045</td>\n",
              "      <td>0.237844</td>\n",
              "      <td>0.765986</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.044181</td>\n",
              "      <td>0.158173</td>\n",
              "      <td>0.847487</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.032480</td>\n",
              "      <td>0.124039</td>\n",
              "      <td>0.879680</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.026261</td>\n",
              "      <td>0.106693</td>\n",
              "      <td>0.895760</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.023198</td>\n",
              "      <td>0.093723</td>\n",
              "      <td>0.909830</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.021653</td>\n",
              "      <td>0.085250</td>\n",
              "      <td>0.916363</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>9</td>\n",
              "      <td>0.020876</td>\n",
              "      <td>0.078474</td>\n",
              "      <td>0.922896</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>10</td>\n",
              "      <td>0.020203</td>\n",
              "      <td>0.073072</td>\n",
              "      <td>0.929428</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>11</td>\n",
              "      <td>0.019610</td>\n",
              "      <td>0.068250</td>\n",
              "      <td>0.933982</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>12</td>\n",
              "      <td>0.019136</td>\n",
              "      <td>0.064343</td>\n",
              "      <td>0.935490</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>13</td>\n",
              "      <td>0.018577</td>\n",
              "      <td>0.060719</td>\n",
              "      <td>0.940013</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>14</td>\n",
              "      <td>0.017983</td>\n",
              "      <td>0.056904</td>\n",
              "      <td>0.945006</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>15</td>\n",
              "      <td>0.017606</td>\n",
              "      <td>0.053434</td>\n",
              "      <td>0.948524</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>16</td>\n",
              "      <td>0.017308</td>\n",
              "      <td>0.050295</td>\n",
              "      <td>0.951036</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>17</td>\n",
              "      <td>0.017168</td>\n",
              "      <td>0.048580</td>\n",
              "      <td>0.952544</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>18</td>\n",
              "      <td>0.016964</td>\n",
              "      <td>0.046670</td>\n",
              "      <td>0.953549</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>19</td>\n",
              "      <td>0.016703</td>\n",
              "      <td>0.046576</td>\n",
              "      <td>0.954020</td>\n",
              "      <td>00:00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "AND THAT IS HOW WE BUILD A NEURAL NET."
      ],
      "metadata": {
        "id": "M3i0r2iqjg5g"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "4BITvAgRJLnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "a29jkPiYJL87"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YaK2YhiXJMAP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xqtCwQBNJMEH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "24KvfX-8JMJ5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZDXhUea-JMNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "u61K_mNKJMRD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MCwfjSBtJMUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Tv_IkMF5JMXl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zXEI03VoJMbJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}